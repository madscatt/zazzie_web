#!/share/apps/local/bin/python/bin/python
import json,sys,os,shutil,time,locale
from StringIO import StringIO
import multiprocessing,time,string,socket

import sassie.tools.merge_utilities as merge_utilities
import sassie.interface.input_filter as input_filter
import sassie.interface.merge_utilities_filter as merge_utilities_filter

class Merge_utilities_Drv():

   module = 'merge_utilities'

   def message_box(self,text,icon):

        _message = {}
        _message['icon'] = icon
        _message['text'] = text

        UDP_IP = json_variables['_udphost']
        UDP_PORT = json_variables['_udpport']
        sock = socket.socket(socket.AF_INET, # Internet
                socket.SOCK_DGRAM) # UDP

        socket_dict={}
        socket_dict['_uuid'] = json_variables['_uuid']
        socket_dict['_message'] = _message

        doc_string = json.dumps(socket_dict)
        sock.sendto(doc_string,(UDP_IP,UDP_PORT))

        return

   def background_job(self,process,txtQueue,json_variables):

        total_string = ''

        UDP_IP = json_variables['_udphost']
        UDP_PORT = json_variables['_udpport']
        sock = socket.socket(socket.AF_INET, # Internet
                socket.SOCK_DGRAM) # UDP

        socket_dict={}
        socket_dict['_uuid'] = json_variables['_uuid']
	first = True

        while process.is_alive():
                try:
                        if(first):
                                socket_dict['progress_html'] = 0.01
                                socket_dict['_progress'] = 0.01
                                socket_dict['progress_html'] = '<center>starting job</center>'
                                doc_string = json.dumps(socket_dict)
                                sock.sendto(doc_string,(UDP_IP,UDP_PORT))
                                first = False
                        this_text = txtQueue.get(True, timeout=0.1)
                        text_split=string.split(this_text)
                        if(text_split[0]=='STATUS'):
                                value = locale.atof(text_split[1])
                                svalue = str(round(100*value,2))
                                socket_dict['progress_output'] = value
                                socket_dict['_progress'] = value
                                socket_dict['progress_html'] = '<center>'+svalue+'</center>'
                                if "_textarea" in socket_dict:
                                        del socket_dict["_textarea"]
                                if socket_dict:
                                        doc_string = json.dumps(socket_dict)
                                        sock.sendto(doc_string,(UDP_IP,UDP_PORT))
                        else:
                                socket_dict["_textarea"] = this_text
                                if socket_dict:
                                        doc_string = json.dumps(socket_dict)
                                        sock.sendto(doc_string,(UDP_IP,UDP_PORT))        
                                total_string += this_text
                except:
                        if not process.is_alive():
                                return total_string

                time.sleep(0.01)
        else:
                return total_string

        return total_string

   def run_me(self,json_flag,json_variables,input_string):

	output_dict = {}

	if not json_flag:

        	#### BEGIN USER EDIT
        	#### BEGIN USER EDIT
        	#### BEGIN USER EDIT

        	runname='run_0'
        	pdb_file='min3.pdb'
    		merge_option = '0'   # 0 -> pdb/dcd:sas ; 1 -> sas ; 2 -> pdb/dcd
    		#merge_option = '2'   # 0 -> pdb/dcd:sas ; 1 -> sas ; 2 -> pdb/dcd
    		number_of_runs = '2'
    		trajectory_names = 'run_m1/generate/run_m1.dcd,run_m2/generate/run_m2.dcd'
    		#trajectory_names = 'generate/run_m1.pdb,generate/run_m2.pdb'
    		sas_type = '1'      # 1 -> xtal2sas, 2 -> cryson, 3 -> cyrsol
    		sas_paths = 'run_m1/xtal2sas,run_m1/xtal2sas'
    		merge_type_option = '0'   # 0 -> all, 1->weight files, 2-> periodic

		local_value = 'None'
    		#local_value = 'weights_file_m1.txt,weights_file_m2.txt'
    		#local_value = '10'

    		output_filename = 'merged_run_0.dcd'
    		#output_filename = 'merged_run_0.pdb'

        	path='./'

        	#### END USER EDIT
        	#### END USER EDIT
        	#### END USER EDIT
       	else:
		runname = json_variables['runname']

                base_directory = json_variables['_base_directory']

                path = base_directory.replace('\/','/') + "/"

                os.chdir(path)
                path = ''

		number_of_runs = json_variables['number_of_runs_to_merge']
		
		try:
			trajectory_checkbox = json_variables['trajectory_checkbox']
		except:		
			trajectory_checkbox = 'off'
		try:
			sas_checkbox = json_variables['sas_checkbox']
		except:		
			sas_checkbox = 'off'

		if(trajectory_checkbox == 'on' and sas_checkbox == 'on'):
			merge_option = '0'
		elif(trajectory_checkbox == 'off' and sas_checkbox == 'on'):
			merge_option = '1'
		elif(trajectory_checkbox == 'on' and sas_checkbox == 'off'):
			merge_option = '2'


		pdb_file = ''
		trajectory_names = ''
		output_filename = ''
		sas_path_names = ''
		sas_type = '1'

		if (merge_option == '0' or merge_option == '2'):

			pdb_file = json_variables['pdb_file'][0]
               
			trajectory_names = ''
			for i in xrange(int(number_of_runs)):
				this_name = json_variables['trajectory_names'][i]
				trajectory_names += this_name[0] + ','

			trajectory_names = trajectory_names[:-1]

			output_filename = json_variables['output_filename']
				
		if (merge_option == '0' or merge_option == '1'):
			sas_path_names = ''
			for i in xrange(int(number_of_runs)):
				this_path = json_variables['sas_paths'][i]

				sas_path_names += this_path[0] + ','

			sas_path_names = sas_path_names[:-1]
                 
			sas_type_list_box = json_variables['sas_type_list_box']
                	if(sas_type_list_box == 'c1'):
                        	sas_type = '1'
                	elif(sas_type_list_box == 'c2'):
                	        sas_type = '2'
                	elif(sas_type_list_box == 'c3'):
                	        sas_type = '3'

		merge_option_list_box = json_variables['merge_option_list_box']
                if(merge_option_list_box == 'c1'):
                        merge_type_option = '0'
                        local_value = 'None'
                elif(merge_option_list_box == 'c2'):
                        merge_type_option = '1'
			local_value = ''
			for i in xrange(int(number_of_runs)):
				this_path = json_variables['weight_files'][i]

				local_value += this_path[0] + ','

			local_value = local_value[:-1]

                elif(merge_option_list_box == 'c3'):
                        merge_type_option = '2'
                        local_value = json_variables['sampling_frequency']

	svariables={}

	svariables['runname'] = (str(runname),'string')
	svariables['pdb_file']  = (str(pdb_file),'string')
	svariables['merge_option']  = (str(merge_option),'int')
	svariables['merge_type_option']  = (str(merge_type_option),'int')
	svariables['number_of_runs']  = (str(number_of_runs),'int')
	svariables['trajectory_names']   = (str(trajectory_names),'string')
	svariables['sas_type']   = (str(sas_type),'int')
	svariables['sas_paths']   = (str(sas_path_names),'string')
	svariables['output_filename']   = (str(output_filename),'string')
	svariables['local_value']   = (str(local_value),'string')
	svariables['path']    = (path,'string')

	error,self.variables=input_filter.type_check_and_convert(svariables)

        if(len(error)>0):

                self.message_box(error,'skull.png')
#               warning.png, information.png, skull.png, toast.png

                output_dict['error'] = 'Error in input variables'
                output_dict['sasoutput2'] = 'run failed'
                print json.dumps( output_dict )
                return
        else:
		error=merge_utilities_filter.check_merge_utilities(self.variables)

                if(len(error) != 0):
                        self.message_box(error,'warning.png')
                        output_dict['error'] = 'Error in merge variables'
                        output_dict['sasoutput2'] = 'run failed'
                        print json.dumps( output_dict )
                        return

		runname=self.variables['runname'][0]

		if os.path.exists(runname+'/'+self.module):
			shutil.rmtree(runname+'/'+self.module)

		txtQueue=multiprocessing.JoinableQueue()

                process=multiprocessing.Process(target=merge_utilities.merge_runs,args=(self.variables,txtQueue))
                process.start()

                total_string = self.background_job(process,txtQueue,json_variables)

#		output_dict['sasoutput2'] = total_string

        if total_string:
                output_dict['_empty_return'] = 1
                print json.dumps( output_dict )
        else:
                error_string = 'Exception encountered executing '+self.module+' program: please submit feedback and attach run log'
                output_dict['error'] = error_string
#                output_dict['_empty_return'] = 1
                print json.dumps( output_dict )

if __name__=='__main__':

	json_flag = True
	#json_flag = False

	if (len(sys.argv) < 1):
		print "\{\"error\":\"merge utilities called with no arguments\"\}\n";
# 		print 'exiting now'

	elif len(sys.argv) > 1:
		json_variables = " "
		if(json_flag):
			argv_io_string = StringIO(sys.argv[1])
			json_variables = json.load(argv_io_string)
		a=Merge_utilities_Drv()
		a.run_me(json_flag,json_variables,sys.argv[1])

